{"path":"sem5/CD/Mod2/Module 2 - Part I-1.pdf","text":"BCSE307L – COMPILER DESIGN 12 Syntax analysis Introduction to Syntax Analysis CFG Types of Parser 3 The role of parser Lexical Analyzer ParserSource program token getNext Token Symbol table Parse tree Rest of Front End Intermediate representation • Parser works on a stream of tokens. • The smallest item is a token. 4 Syntax Analyzer Syntax Analyzer creates the syntactic structure of the given source program. This syntactic structure is mostly a parse tree. Syntax Analyzer is also known as parser. The syntax of a programming is described by a context-free grammar (CFG). 5 Syntax Analyzer(contd..) The syntax analyzer (parser) checks whether a given source program satisfies the rules implied by a context-free grammar or not. ◦ If it satisfies, the parser creates the parse tree of that program. ◦ Otherwise the parser gives the error messages. A context-free grammar ◦ gives a precise syntactic specification of a programming language. ◦ the design of the grammar is an initial phase of the design of a compiler. ◦ a grammar can be directly converted into a parser by some tools. 6 Expression Grammar 78 Parsers We categorize the parsers into two groups: 1. Top-Down Parser ◦ the parse tree is created top to bottom, starting from the root. 2. Bottom-Up Parser ◦ the parse is created bottom to top; starting from the leaves Both top-down and bottom-up parsers scan the input from left to right (one symbol at a time). Efficient top-down and bottom-up parsers can be implemented only for sub-classes of context-free grammars. ◦ LL for top-down parsing ◦ LR for bottom-up parsing Syntax Error Handling ▪Lexical Errors ▪Syntactic Errors ▪Semantic Errors ▪Logical Errors 9 Syntax Error Handling Lexical Errors ◦ Misspellings of identifiers, Keywords, Operators…. ◦ Ex: identifier elipseSize instead of ellipseSize Syntactic Errors ◦ Misplaced semicolons or missing braces Semantic Errors ◦ Mismatches between operators and operands Logical Errors ◦ It can be anything from incorrect reasoning on the part of the programmer Error-recovery strategies Panic mode recovery ◦ Discard input symbol one at a time until one of designated set of synchronization tokens is found Phrase level recovery ◦ Replacing a prefix of remaining input by some string that allows the parser to continue Error productions ◦ Augment the grammar with productions that generate the erroneous constructs Global correction ◦ Choosing minimal sequence of changes to obtain a globally least-cost correction 11 Syntax Tree A parse tree is a record of the rules (and tokens) used to match some input text A syntax tree records the structure of the input and is insensitive to the grammar that produced it. 121314 CONTEXT FREE GRAMMAR (CFG) ❑The formal definition of a context-free grammar ❑Notational Conventions ❑Derivations ❑Parse Tree and Derivations ❑Ambiguity ❑Verifying the language generated by a Grammar ❑Context-free grammar versus regular expression 15 Context-Free Grammars Inherently recursive structures of a programming language are defined by a context-free grammar. In a context-free grammar G = (V,T,P,S), we have: ◦ T - A finite set of terminals (in our case, this will be the set of tokens) ◦ V - A finite set of non-terminals (syntactic-variables) ◦ P - A finite set of productions rules in the following form ◦ A →  where A is a non-terminal and  is a string of terminals and non-terminals (including the empty string) ◦ S - A start symbol (one of the non-terminal symbol) 16 Notational Conventions 1718 Notational Conventions Example 19 Expression Grammar Example: E → E + E | E – E | E * E | E / E | - E E → ( E ) E → id 20 CFG - Terminology L(G) is the language of G (the language generated by G) which is a set of sentences. A sentence of L(G) is a string of terminal symbols of G. If S is the start symbol of G then  is a sentence of L(G) iff S   where  is a string of terminals of G. If G is a context-free grammar, L(G) is a context-free language. Two grammars are equivalent if they produce the same language. S   - If  contains non-terminals, it is called as a sentential form of G. - If  does not contain non-terminals, it is called as a sentence of G. + * 21 Derivations A sequence of replacements of non-terminal symbols is called a derivation of id+id from E. 1  2  ...  n (n derives from 1 or 1 derives n )  : derives in one step  : derives in zero or more steps  : derives in one or more steps * + 22 Derivations 23 Derivations E  E+E E+E derives from E ◦ we can replace E by E+E ◦ to able to do this, we have to have a production rule E→E+E in our grammar. E  E+E  id+E  id+id 24 Derivation Example E  -E  -(E)  -(E+E)  -(id+E)  -(id+id) OR E  -E  -(E)  -(E+E)  -(E+id)  -(id+id) At each derivation step, we can choose any of the non-terminal in the sentential form of G for the replacement. If we always choose the left-most non-terminal in each derivation step, this derivation is called as left-most derivation. If we always choose the right-most non-terminal in each derivation step, this derivation is called as right-most derivation. 25 Left-Most and Right-Most Derivations Left-Most Derivation E  -E  -(E)  -(E+E)  -(id+E)  -(id+id) Right-Most Derivation E  -E  -(E)  -(E+E)  -(E+id)  -(id+id) We will see that the top-down parsers try to find the left-most derivation of the given source program. We will see that the bottom-up parsers try to find the right-most derivation of the given source program in the reverse order. lmlmlmlmlm rmrmrmrmrm 26 Parse Tree • Inner nodes of a parse tree are non-terminal symbols. • The leaves of a parse tree are terminal symbols. • A parse tree can be seen as a graphical representation of a derivation. E  -E E E- E E EE E + - ( ) E E E- ( ) E E id E E E + - ( ) id E E E EE + - ( ) id  -(E)  -(E+E)  -(id+E)  -(id+id) 27 Ambiguity • A grammar produces more than one parse tree for a sentence is called as an ambiguous grammar. E  E+E  id+E  id+E*E  id+id*E  id+id*id E  E*E  E+E*E  id+E*E  id+id*E  id+id*id E id E + id id E E * E E E + id E E * E id id 28 Ambiguous: Two Different Parse Tree: Ambiguity Ambiguous: Two Different Parse Tree: if E1 then if E2 then S1 else S2 One Parse Tree: if E1 then S1 else if E2 then S2 else S3 29 Ambiguity For the most parsers, the grammar must be unambiguous. unambiguous grammar ➔ unique selection of the parse tree for a sentence We should eliminate the ambiguity in the grammar during the design phase of the compiler. An unambiguous grammar should be written to eliminate the ambiguity. We have to prefer one of the parse trees of a sentence (generated by an ambiguous grammar) to disambiguate that grammar to restrict to this choice. 30 Verifying the language generated by a Grammar Expression S → (S) S | Ɛ S  (S) S (x)S  (x)y Checking the string (x)y is balanced with equal number of right and left parentheses and every prefix has at least as many left parentheses as right w  (x)y is also derivable form S. 31 lmlm lm Context-free grammar versus regular expression R.E = (a|b)*abb CFG: S → aS | bS | aA A → bB B → bC C → Ɛ 32 Writing a Grammar ❑Lexical versus Syntactic Analysis ❑Eliminating Ambiguity ❑Elimination of Left Recursion ❑Elimination of left Factoring 33 Elimination of ambiguity Idea: ◦ A statement appearing between a then and an else must be matched (Match each else with the closest previous unmatched then ) 34 Ambiguity • We prefer the first parse tree (else matches with closest if). • So, we have to disambiguate our grammar to reflect this choice. • The unambiguous grammar will be: stmt → matched_stmt | unmatched_stmt matchedstmt → if expr then matched_stmt else matchedstmt | otherstmts unmatchedstmt → if expr then stmt | if expr then matched_stmt else unmatched_stmt 35 Expression Grammar Example: E → E + E | E – E | E * E | E / E | - E E → ( E ) E → id 36 Simple Arithmetic Expression (Unambiguous Expression) Grammar expr → expr + term expr → expr - term expr → term term → term * factor term → term / factor term → factor factor → (expr) factor → id 37 Unambiguous Expression Grammar E → E + T | E – T | T T → T * F | T / F | F F → ( E ) F → id 38 Left Recursion A grammar is left recursive if it has a non-terminal A such that there is a derivation. A  A for some string  Top-down parsing techniques cannot handle left-recursive grammars. So, we have to convert our left-recursive grammar into an equivalent grammar which is not left-recursive. The left-recursion may appear in a single step of the derivation (immediate left- recursion), or may appear in more than one step of the derivation. + 39 Immediate Left-Recursion A → A  |  where  does not start with A  eliminate immediate left recursion A →  A’ A’ →  A’ |  an equivalent grammar A → A 1 | ... | A m | 1 | ... | n where 1 ... n do not start with A  eliminate immediate left recursion A → 1 A’ | ... | n A’ A’ → 1 A’ | ... | m A’ |  an equivalent grammar In general, 40 Immediate Left-Recursion -- Example E → E+T | T T → T*F | F F → (E) F → id E → T E’ E’ → +T E’ |  T → F T’ T’ → *F T’ |  F → (E) F → id eliminate immediate left recursion  4142 Apply Left recursion for this example: 43 E → E + T | E – T | T T → T * F | T / F | F F → ( E ) F → id 44 LHS → RHS S → P1 | P2 | P3 | …. | Pn Rule: A → A  |   A →  A’ A’ →  A’ |  Elimination of left recursion Example 2 S → Aa | b A → Ac | Sd |  45 Example 2 S → Aa | b A → Ac | Sd |  A → Ac | Aad | bd |  A → A1 |A2 |1 | 2 S → Aa | b A → bdA’ | A’ A’ → cA’ | adA’ |  46 Elimination of Left Factoring 47 A predictive parser (a top-down parser without backtracking) insists that the grammar must be left-factored. grammar ➔ a new equivalent grammar suitable for predictive parsing stmt → if expr then stmt else stmt | if expr then stmt Elimination of Left-Factoring In general, A → 1 | 2 where  is non-empty and the first symbols of 1 and 2 (if they have one ) are different. 48 Elimination of Left-Factoring But, if we re-write the grammar as follows A → A’ A’ → 1 | 2 so, we can immediately expand A to A’ 4950 Algorithm For each non-terminal A with two or more alternatives (production rules) with a common non-empty prefix, let say A → 1 | ... | n | 1 | ... | m convert it into A → A’ | 1 | ... | m A’ → 1 | ... | n Left-Factoring 51 S → i E t S | i E t S e S | a E → b Example 1 52 S → i E t S S’ | a S’ → e S |  E → b Removal of Left FactoringExample 2 – Removal of Left Factoring A → ad | a | ab | abc | b  A → aA’ | b A’ → d |  | b | bc  A → aA’ | b A’ → d |  | bA’’ A’’ →  | c 53 A → abB | aB | cdg | cdeB | cdfB  A → aA’ | cdg | cdeB | cdfB A’ → bB | B  A → aA’ | cdA’’ A’ → bB | B A’’ → g | eB | fB Example 3 - Removal of Left Factoring 54 Parsing Technique We categorize the parsers into two groups: 1. Top-Down Parsing ◦ the parse tree is created top to bottom, starting from the root. 2. Bottom-Up Parsing ◦ the parse is created bottom to top; starting from the leaves Both top-down and bottom-up parsers scan the input from left to right (one symbol at a time). Efficient top-down and bottom-up parsers can be implemented only for sub- classes of context-free grammars. ◦ LL for top-down parsing ◦ LR for bottom-up parsing 55 Top Down Parsing ❑Recursive-Descent Parsing ❑Non-Recursive Predictive Parsing 56 Top Down Parser A Top-down parser tries to create a parse tree from the root towards the leafs scanning input from left to right It can be also viewed as finding a leftmost derivation for an input string Example: id+id*id Top-Down Parsing 58 Recursive-Descent Parsing 59 Recursive-Descent Parsing 60 Recursive-Descent Parsing 61 Non-Recursive Predictive Parsing 62 Non-Recursive Predictive Parsing / Top Down Parser / LL(1) LL(1) Grammar ❑Elimination of Left Recursion / Left Factoring ❑FIRST and FOLLOW ❑Predictive parsing table ❑Stack Implementation 63 LL(1) Grammar Predictive Parser, i.e recursive-descent parsers without backtracking is constructed for a class of grammar called LL(1) ❑L – Leftmost derivation ❑L – scans the input from left to right ❑1 – one input symbol of lookahead at each step to make parsing action 64 Elimination of Left Recursion E → E+T | T T → T*F | F F → (E) F → id E → T E’ E’ → +T E’ |  T → F T’ T’ → *F T’ |  F → (E) F → id  65 FIRST and FOLLOW FIRST(X): Rules: 1. X is a Terminal, FIRST (X) = { X } 2. X is a Non-terminal, X → Y1, Y2, Y3 . . . . Yk , K ≥ 1, FIRST(X) = FIRST(Y1) 3. X → ε is a production, FIRST(X) = { ε } 66 FIRST(x): 1 ) E → T E’ FIRST ( E) = FIRST (T) 2) E’ → +T E’ |  E’ → +T E’ E’ →  FIRST(E’) = + FIRST (E’) =  67 3)T → F T’ FIRST(T) = FIRST(F) 4)T’ → *F T’ |  T’ → *F T’ T’ →  FIRST(T’) = * FIRST(T’) =  68 FIRST(x): 69 5) F → (E) FIRST(E) = ( 6) F → id FIRST(E) = id FIRST(x):FIRST (X) 70 Non- terminal FIRST E ( , id E’ + , ε T ( , id T’ * , ε F ( , id FIRST and FOLLOW FOLLOW(X): Rules: 1. S is a Start Symbol, FOLLOW(S) = $ 2. If a production A → α B β , FOLLOW(B) = FIRST(β) – ε 3. If a production A → α B or A → α B β i.e, FIRST(β) = ε FOLLOW (B) = FOLLOW(A) 71 FOLLOW(X) 1) E → T E’ FOLLOW(T) = FIRST(E’)-ε = + , ε – ε = + FOLLOW(T) = FOLLOW(E) FOLLOW(T) = + , FOLLOW(E) 72 FOLLOW(X) 1) E → T E’ FOLLOW(E’) = FOLLOW(E) FOLLOW(E’) = FOLLOW(E) 73 FOLLOW(X) 2) E’ → +T E’ |  FOLLOW(T) = FIRST(E’)-ε = + , ε – ε = + FOLLOW(T) = FOLLOW(E’) FOLLOW(T) = + , FOLLOW(E’) 74 FOLLOW(X) 2) E’ → +T E’ |  FOLLOW(E’) = FOLLOW(E’) FOLLOW(E’) = FOLLOW(E’) 75 FOLLOW(X) 3) T → F T’ FOLLOW(F) = FIRST(T’)-ε = * , ε – ε = * FOLLOW(F) = FOLLOW(T) FOLLOW(F) = * , FOLLOW(T) 76 FOLLOW(X) 3) T → F T’ FOLLOW(T’) = FOLLOW(T) FOLLOW(T’) = FOLLOW(T) 77 FOLLOW(X) 4) T’ → *F T’ |  FOLLOW(F) = FIRST(T’)-ε = * , ε – ε = * FOLLOW(F) = FOLLOW(T’) FOLLOW(F) = * , FOLLOW(T’) 78 FOLLOW(X) 4) T’ → *F T’ |  FOLLOW(T’) = FOLLOW(T’) FOLLOW(T’) = FOLLOW(T’) 79 FOLLOW(X) 5 ) F → (E) FOLLOW(E) = FIRST( ‘)’ ) = ) FOLLOW(E) = $ FOLLOW(E) = { ) , $ } 80 FOLLOW(X) 6) F → id 81 FOLLOW Non-terminal FOLLOW E ) , $ E’ FOLL(E’) = FOLL(E) FOLL(E’) = FOLL(E’) T FOLL(T) = + , FOLL(E) FOLL(T) = +, FOLL(E’) T’ FOLL(T’) = FOLL(T) FOLL(T’) = FOLL(T’) F FOLL(F) = * , FOLL(T) FOLL(F) = * , FOLL(T’) 82 FOLLOW Non- terminal FOLLOW FOLLOW E ) , $ ) , $ E’ FOLLOW(E) , FOLLOW(E’) ) , $ T + , FOLLOW(E) , FOLLOW(E’) +, ) , $ T’ FOLLOW(T), FOLLOW(T’) +, ) , $ F * , FOLLOW(T), FOLLOW(T’) * , +, ) , $ 83 FIRST and FOLLOW Non- terminal FIRST FOLLOW E ( , id ) , $ E’ + , ε ) , $ T ( , id +, ) , $ T’ * , ε +, ) , $ F ( , id * , +, ) , $ 8485 Non-Recursive Predictive ParsingPredicting parsing Table 86 Stack Implementation 87 Stack Implementation 88 Table-driven Predictive Parsing Stack Input Action $E id + id * id $ push E → TE’ $E’T id + id * id $ push T → FT’ $E’T’F id + id * id $ push F → id $E’T’id id + id * id $ pop (match id) $E’T’ + id * id $ push T’ → ε $E’ + id * id $ push E’ → +TE’ $E’T+ + id * id $ pop (match +) $E’T id * id $ push T → FT’ 89 Table-driven Predictive Parsing Stack Input Action $E’T’F id * id $ push F → id $E’T’id id * id $ pop (match id) $E’T’ * id$ push T’ → *FT’ $E’T’F* *id$ pop (match *) $E’T’F id$ push F → id $E’T’id id$ pop (match id) $E’T’ $ push T’ → ε $E’ $ push E’ → ε $ $ Accept 90 Table-driven Predictive Parsing 91 Error Recovery in Predictive Parsing Error is detected in predictive parsing, M[A,a] is error ▪Panic mode ▪Phrase-level recovery 92 Panic mode ▪Skipping symbols on the input until a token in a selected set of synchronizing tokens appears. ▪FOLLOW(A) ▪The synchronizing set for nonterminal A ▪Eg: if semicolons terminate statements as in C ▪FIRST(A) ▪Add to the synchronizing set for nonterminal A ▪NT produces the empty string ▪Terminal cannot be matched, pop the terminal 93 Predictive Parsing Table 94 Parsing and Error Recovery 95 Phrase-level recovery ▪It is implemented by filling in the blank entries in the predictive parsing table with pointers to error routines. ▪These routines may change, insert, or delete symbols on the input and issue appropriate error messages. 96 Thank You 97","libVersion":"0.5.0","langs":""}