{"path":"sem5/AI/15281_Fa19_Lecture_6_Local_Search_inked.pdf","text":"Local Search Warm-up How to find the top of Mount Everest in a thick fog while suffering from amnesia? AI: Representation and Problem Solving Local Search Instructors: Fei Fang & Pat Virtue Slide credits: CMU AI, http://ai.berkeley.edu Learning Objectives â€¢ Describe and implement the following local search algorithms â€¢ Iterative improvement algorithm with min-conflict heuristic for CSPs â€¢ Hill Climbing (Greedy Local Search) â€¢ Random Walk â€¢ Simulated Annealing â€¢ Beam Search â€¢ Genetic Algorithm â€¢ Identify completeness and optimality of local search algorithms â€¢ Compare different local search algorithms as well as contrast with classical search algorithms â€¢ Select appropriate local search algorithms for real-world problems Local Search â€¢ Can be applied to identification problems (e.g., CSPs), as well as some planning and optimization problems â€¢ Typically use a complete-state formulation, e.g., all variables assigned in a CSP (may not satisfy all the constraints) Iterative Improvement for CSPsIterative Improvement for CSPs â€¢ Start with an arbitrary assignment, iteratively reassign variable values â€¢ While not solved, â€¢ Variable selection: randomly select a conflicted variable â€¢ Value selection with min-conflicts heuristic â„: Choose a value that violates the fewest constraints (break tie randomly) â€¢ For ğ‘›-Queens: Variables ğ‘¥ğ‘– âˆˆ {1. . ğ‘›}; Constraints ğ‘¥ğ‘– â‰  ğ‘¥ğ‘—, ğ‘¥ğ‘– âˆ’ ğ‘¥ğ‘— â‰  ğ‘– âˆ’ ğ‘— , âˆ€ğ‘– â‰  ğ‘— Demo â€“ ğ‘›-Queens [Demo: n-queens â€“ iterative improvement (L5D1)] Demo â€“ Graph ColoringIterative Improvement for CSPs â€¢ Given random initial state, can solve n-queens in almost constant time for arbitrary n with high probability (e.g., n = 10,000,000)! â€¢ Same for any randomly-generated CSP except in a narrow range of the ratio Local Search â€¢ A local search algorithm isâ€¦ â€¢ Complete if it always finds a goal if one exists â€¢ Optimal if it always finds a global minimum/maximum Is Iterative Improvement for CSPs complete? No! May get stuck in a local optima â„ = 1 State-Space Landscape In identification problems, could be a function measuring how close you are to a valid solution, e.g., âˆ’1 Ã— #conflicts in n-Queens/CSP Whatâ€™s the difference between shoulder and flat local maximum (both are plateaux)? Hill Climbing (Greedy Local Search) â€¢ Simple, general idea: â€¢ Start wherever â€¢ Repeat: move to the best â€œneighboringâ€ state (successor state) â€¢ If no neighbors better than current, quit Complete? Optimal? No! No! Hill Climbing (Greedy Local Search) How to apply Hill Climbing to ğ‘›-Queens? How is it different from Iterative Improvement? Define a state as a board with ğ‘› queens on it, one in each column Define a successor (neighbor) of a state as one that is generated by moving a single queen to another square in the same column How many successors? Hill Climbing (Greedy Local Search) What if there is a tie? Typically break ties randomly â€¢ In 8-Queens, steepest-ascent hill climbing solves 14% of problem instances â€¢ Takes 4 steps on average when it succeeds, and 3 steps when it fails â€¢ When allow for â‰¤100 consecutive sideway moves, solves 94% of problem instances â€¢ Takes 21 steps on average when it succeeds, and 64 steps when it fails What if we do not stop here? Make a sideway move if â€œ=â€ Variants of Hill Climbing â€¢ Random-restart hill climbing â€¢ â€œIf at first you donâ€™t succeed, try, try again.â€ â€¢ Complete! â€¢ What kind of landscape will random-restarts hill climbing work the best? â€¢ Stochastic hill climbing â€¢ Choose randomly from the uphill moves, with probability dependent on the â€œsteepnessâ€ (i.e., amount of improvement) â€¢ Converge slower than steepest ascent, but may find better solutions â€¢ First-choice hill climbing â€¢ Generate successors randomly (one by one) until a better one is found â€¢ Suitable when there are too many successors to enumerate Variants of Hill Climbing â€¢ What if variables are continuous, e.g. find ğ‘¥ âˆˆ [0,1] that maximizes ğ‘“ ğ‘¥ ? â€¢ Gradient ascent â€¢ Use gradient to find best direction â€¢ Use the magnitude of the gradient to determine how big a step you move Value space of variables Piazza Poll: Hill Climbing 1. Starting from X, where do you end up? 2. Starting from Y, where do you end up? 3. Starting from Z, where do you end up? A: ğ‘‹ â†’ ğ´, ğ‘Œ â†’ ğ·, ğ‘ â†’ ğ¸ B: ğ‘‹ â†’ ğµ, ğ‘Œ â†’ ğ·, ğ‘ â†’ ğ¸ C: ğ‘‹ â†’ ğ‘‹, ğ‘Œ â†’ ğ¶, ğ‘ â†’ ğ‘ Random Walk â€¢ Uniformly randomly choose a neighbor to move to â€¢ Complete but inefficient! Simulated Annealing â€¢ Combines random walk and hill climbing â€¢ Complete and efficient â€¢ Inspired by statistical physics â€¢ Annealing â€“ Metallurgy â€¢ Heating metal to high temperature then cooling â€¢ Reaching low energy state â€¢ Simulated Annealing â€“ Local Search â€¢ Allow for downhill moves and make them rarer as time goes on â€¢ Escape local maxima and reach global maxima Simulated Annealing Almost the same as hill climbing except for a random successor Unlike hill climbing, move downhill with some prob. Control the change of temperature ğ‘‡ (â†“ over time) Simulated Annealing â€¢ â„™ move downhill = ğ‘’Î”ğ¸/ğ‘‡ â€¢ Bad moves are more likely to be allowed when ğ‘‡ is high (at the beginning of the algorithm) â€¢ Worse moves are less likely to be allowed â€¢ Stationary distribution: â€¢ Guarantee: If ğ‘‡ decreased slowly enough, will converge to optimal state! â€¢ But! In reality, the more downhill steps you need to escape a local optimum, the less likely you are to ever make them all in a row Local Beam Search â€¢ Keep track of ğ‘˜ states â€¢ In each iteration â€¢ Generate all successors of all ğ‘˜ states â€¢ Only retain the best ğ‘˜ successors among them all Analogous to evolution / natural selection! The searches communicate! â€œCome over here, the grass is greener!â€ How is this different from ğ¾ local searches with different initial states in parallel? Limitations and Variants of Local Beam Search â€¢ Suffer from a lack of diversity; Quickly concentrated in a small region of the state space â€¢ Variant: Stochastic beam search â€¢ Randomly choose ğ‘˜ successors (offsprings) of a state (organism) population according to its objective value (fitness) Genetic Algorithms â€¢ Inspired by evolutionary biology â€¢ Nature provides an objective function (reproductive fitness) that Darwinian evolution could be seen as attempting to optimize â€¢ A variant of stochastic beam search â€¢ Successors are generated by combining two parent states instead of modifying a single state (sexual reproduction rather than asexual reproduction) Genetic Algorithms for 8-Queens â€¢ State Representation: 8-digit string, each digit in {1. . 8} â€¢ Fitness Function: #Nonattacking pairs â€¢ Selection: Select ğ‘˜ individuals randomly with probability proportional to their fitness value (random selection with replacement) â€¢ Crossover: For each pair, choose a crossover point âˆˆ {1. . 7}, generate two offsprings by crossing over the parent strings â€¢ Mutation (With some prob.): Choose a digit and change it to a different value in {1. . 8} What if ğ‘˜ is an odd number? Genetic Algorithms for 8-Queens â€¢ Why does crossover make sense here? â€¢ Would crossover work well without a selection operator? Genetic Algorithms â€¢ Start with a population of ğ‘˜ individuals (states) â€¢ In each iteration â€¢ Apply a fitness function to each individual in the current population â€¢ Apply a selection operator to select ğ‘˜ pairs of parents â€¢ Generate ğ‘˜ offsprings by applying a crossover operator on the parents â€¢ For each offspring, apply a mutation operation with a (usually small) independent probability â€¢ For a specific problem, need to design these functions and operators â€¢ Successful use of genetic algorithms require careful engineering of the state representation! Genetic Algorithms How is this different from the illustrated procedure on 8-Queens? Exercise: Traveling Salesman Problem â€¢ Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city and returns to the origin city? â€¢ Input: ğ‘ğ‘–ğ‘—, âˆ€ğ‘–, ğ‘— âˆˆ {0, â€¦ , ğ‘› âˆ’ 1} â€¢ Output: A ordered sequence {ğ‘£0, ğ‘£1, â€¦ , ğ‘£ğ‘›} with ğ‘£0 = 0, ğ‘£ğ‘› = 0 and all other indices show up exactly once â€¢ Question: How to apply Local Search algorithms to this problem? Summary: Local Search â€¢ Maintain a constant number of current nodes or states, and move to â€œneighborsâ€ or generate â€œoffspringsâ€ in each iteration â€¢ Do not maintain a search tree or multiple paths â€¢ Typically do not retain the path to the node â€¢ Advantages â€¢ Use little memory â€¢ Can potentially solve large-scale problems or get a reasonable (suboptimal or almost feasible) solution Learning Objectives â€¢ Describe and implement the following local search algorithms â€¢ Iterative improvement algorithm with min-conflict heuristic for CSPs â€¢ Hill Climbing (Greedy Local Search) â€¢ Random Walk â€¢ Simulated Annealing â€¢ Beam Search â€¢ Genetic Algorithm â€¢ Identify completeness and optimality of local search algorithms â€¢ Compare different local search algorithms as well as contrast with classical search algorithms â€¢ Select appropriate local search algorithms for real-world problems","libVersion":"0.5.0","langs":""}