{
  "aiModel": "llama3.1:8b",
  "ollamaURL": "http://localhost:11434",
  "temperature": 0.1,
  "isContextFreeChatsEnabled": false
}